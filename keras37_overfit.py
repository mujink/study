# 딥러닝 = 입출력 함수의 관계를 추론하는 계산 컴퓨팅.
# 과적합 : 훈련 데이터로 훈련시, 최적의 로스와 웨이트를 찾은 상태
# 과적합 문제점 : 훈련 데이터에 최적하된 로스와 웨이트 값을 가짐으로서 다른 데이터 값에 대한 예측 출력 오차가 커짐.

# 과적합을 방지 하는 방법 ===========================================
# 1. 타입스텝(model.fit)의 베치사이즈를 늘린다. = 훈련 데이터를 늘림으로서 오차율의 "평균값" 이 대체로 epochs 마다 일정하게 나오게됨. 
# 2. 피처를 줄인다. = 출력 값과 상관관계가 없는 컬럼 제거(출력 함수의 차수를 강제로 줄임 => 예상치의 곡)
# 3. regwlarization = 정규화 (쓰레기 인, 쓰레기 아웃 방지)
# 4. dropout (딥러닝에 한정)=> 훈련 중 불필요한 일부 노드를 차단함(출력 함수의 차수를 강제로 줄임)

# 5. 앙상블? 통상 2~5% 향상(?)이라 카더라.
